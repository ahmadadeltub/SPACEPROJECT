import cv2
import mediapipe as mp
import serial
import time

# Open serial port (Replace 'COM5' with your Arduino's port)
arduino = serial.Serial('COM5', 9600)
time.sleep(2)  # Wait for the connection to establish

# Initialize MediaPipe Hands model
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(static_image_mode=False,
                       max_num_hands=2,
                       min_detection_confidence=0.7,
                       min_tracking_confidence=0.7)
mp_draw = mp.solutions.drawing_utils

# Initialize the webcam for video capture
cap = cv2.VideoCapture(0)

# Define LED commands for Arduino
RED_LED_COMMAND = b'R'     # Command to turn on the red LED for left index finger up
YELLOW_LED_COMMAND = b'Y'  # Command to turn on the yellow LED for right index finger up
GREEN_LED_COMMAND = b'G'   # Command to turn on the green LED for right thumb up

# Initialize a variable to store the last sent LED command
last_led_command = None

try:
    # Main loop for capturing and processing video frames
    while True:
        # Initialize LED command
        led_command = None
        
        # Read a frame from the webcam
        ret, frame = cap.read()
        if not ret:
            print("Failed to capture frame from webcam.")
            break

        # Flip the frame horizontally to correct mirroring
        frame = cv2.flip(frame, 1)

        # Convert the BGR image to RGB
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # Process the image and detect hands
        results = hands.process(rgb_frame)

        # Draw hand landmarks and connections on the image
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
                
                # Check if it's a left or right hand and the gesture
                for id, lm in enumerate(hand_landmarks.landmark):
                    if id == mp_hands.HandLandmark.THUMB_TIP.value:  # Thumb tip
                        if lm.x < 0.5 and lm.y < hand_landmarks.landmark[mp_hands.HandLandmark.WRIST.value].y:
                            # Left index finger up
                            led_command = RED_LED_COMMAND
                            hand_label = "Left Index Up (Red LED On)"
                        elif lm.x > 0.5 and lm.y < hand_landmarks.landmark[mp_hands.HandLandmark.WRIST.value].y:
                            # Right thumb up
                            led_command = GREEN_LED_COMMAND
                            hand_label = "Right Thumb Up (Green LED On)"
                    elif id == mp_hands.HandLandmark.INDEX_FINGER_TIP.value:  # Index finger tip
                        if lm.x > 0.5 and lm.y < hand_landmarks.landmark[mp_hands.HandLandmark.WRIST.value].y:
                            # Right index finger up
                            led_command = YELLOW_LED_COMMAND
                            hand_label = "Right Index Up (Yellow LED On)"
                
                # Add hand label text to the frame
                cv2.putText(frame, hand_label, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        # Send LED command to Arduino with debouncing
        if led_command and led_command != last_led_command:
            arduino.write(led_command)
            last_led_command = led_command

        # Display the processed image with hand landmarks and hand label
        cv2.imshow('Hand Gesture Recognition', frame)

        # Check for the 'q' key press to exit the loop
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

# Handle any exceptions that may occur
except Exception as e:
    print(f"An error occurred: {e}")

# Release the webcam and close all OpenCV windows
finally:
    cap.release()
    cv2.destroyAllWindows()
    arduino.close()
